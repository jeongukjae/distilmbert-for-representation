{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistilmBERT-LaBSE-KD-MSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNH/tIDlu0Wt4OIXbtOK8D/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongukjae/distilmbert-for-representation/blob/main/knowledge_distillation_mse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeDKwy2Q-gV9",
        "outputId": "812ba3cc-c9fc-43b9-97a2-691566c4d2df"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\"\n",
        "print(os.environ['COLAB_TPU_ADDR'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.69.13.122:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlu1dOO9-2dG"
      },
      "source": [
        "!pip install -U -q tensorflow-text tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PGEVtk-3Yh"
      },
      "source": [
        "HIDDEN_SIZE = 768\n",
        "\n",
        "LEARNING_RATE = 8e-4\n",
        "BATCH_SIZE = 1024\n",
        "STEPS_PER_EPOCH = 1000\n",
        "EPOCHS = 10\n",
        "WARMUP_RATE = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkMOyhml-5u_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRxmZ1DR-6nP",
        "outputId": "6bbfc382-2e2b-4b4f-84ef-e576ed8dc088"
      },
      "source": [
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "strategy = tf.distribute.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.13.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.13.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8NN0la-W6yN"
      },
      "source": [
        "def create_student_preprocessing_model():\n",
        "    return hub.KerasLayer(\"https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2\")\n",
        "\n",
        "def create_teacher_preprocessing_model():\n",
        "    return hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02qFHwIZT_xj"
      },
      "source": [
        "def create_student_model():\n",
        "    encoder = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1\",\n",
        "        trainable=True,\n",
        "    )\n",
        "    inputs = {\n",
        "        \"input_word_ids\": tf.keras.Input([None], dtype=tf.int32, name=\"input_word_ids\"),\n",
        "        \"input_mask\": tf.keras.Input([None], dtype=tf.int32, name=\"input_mask\"),\n",
        "    }\n",
        "    logit = encoder(inputs)['pooled_output']\n",
        "    logit = tf.keras.layers.Dense(HIDDEN_SIZE)(logit)\n",
        "    model = tf.keras.Model(inputs, logit)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def create_teacher_model():\n",
        "    encoder = hub.KerasLayer(\"https://tfhub.dev/google/LaBSE/2\")\n",
        "    inputs = {\n",
        "        \"input_word_ids\": tf.keras.Input([None], dtype=tf.int32, name=\"input_word_ids\"),\n",
        "        \"input_type_ids\": tf.keras.Input([None], dtype=tf.int32, name=\"input_type_ids\"),\n",
        "        \"input_mask\": tf.keras.Input([None], dtype=tf.int32, name=\"input_mask\"),\n",
        "    }\n",
        "    logit = encoder(inputs)['default']\n",
        "    model = tf.keras.Model(inputs, logit)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzLQk-_cXhVG"
      },
      "source": [
        "class ModelForKD(tf.keras.Model):\n",
        "    def __init__(self, model1, model2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model1 = model1\n",
        "        self.model2 = model2\n",
        "\n",
        "    def train_step(self, data):\n",
        "        model1_input, model2_input = data\n",
        "\n",
        "        model2_output = self.model2(model2_input)\n",
        "        model2_output = tf.stop_gradient(model2_output)\n",
        "        with tf.GradientTape() as tape:\n",
        "            model1_output = self.model1(model1_input, training=True)\n",
        "            loss = self.compiled_loss(model2_output, model1_output, regularization_losses=self.losses)\n",
        "\n",
        "        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
        "        self.compiled_metrics.update_state(model2_output, model1_output)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzY9SigWYjR"
      },
      "source": [
        "class BertScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, rate, warmup_ratio, total_steps, name=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rate = rate\n",
        "        self.warmup_ratio = warmup_ratio\n",
        "        self.total_steps = float(total_steps)\n",
        "        self.warmup_steps = warmup_ratio * total_steps\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, step):\n",
        "        with tf.name_scope(\"BertScheduler\"):\n",
        "            total_steps = tf.convert_to_tensor(self.total_steps, name=\"total_steps\")\n",
        "            warmup_steps = tf.convert_to_tensor(self.warmup_steps, name=\"warmup_steps\")\n",
        "\n",
        "            current_step = step + 1.0\n",
        "\n",
        "            return self.rate * tf.cond(\n",
        "                current_step < warmup_steps,\n",
        "                lambda: self.warmup(current_step, warmup_steps),\n",
        "                lambda: self.decay(current_step, total_steps, warmup_steps),\n",
        "            )\n",
        "\n",
        "    @tf.function\n",
        "    def warmup(self, step, warmup_steps):\n",
        "        return step / tf.math.maximum(tf.constant(1.0), warmup_steps)\n",
        "\n",
        "    @tf.function\n",
        "    def decay(self, step, total_steps, warmup_steps):\n",
        "        return tf.math.maximum(\n",
        "            tf.constant(0.0), (total_steps - step) / tf.math.maximum(tf.constant(1.0), total_steps - warmup_steps)\n",
        "        )\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            \"warmup_ratio\": self.warmup_ratio,\n",
        "            \"total_steps\": self.total_steps,\n",
        "            \"warmup_steps\": self.warmup_steps,\n",
        "            \"name\": self.name,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSm2rjjYD1CB"
      },
      "source": [
        "LANGS = ['ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'hi', 'ru', 'sw', 'th', 'tr', 'ur', 'vi', 'zh']\n",
        "NUM_LANGS = len(LANGS)\n",
        "\n",
        "\n",
        "def get_xnli_dataset(student_preprocessor, teacher_preprocessor, batch_size, tfds_name=\"xtreme_xnli\"):\n",
        "    with tf.device('/job:localhost'):\n",
        "        # batch_size=-1 is a way to load the dataset into memory\n",
        "        in_memory_ds = tfds.load(tfds_name, split='train', batch_size=-1, shuffle_files=True)\n",
        "\n",
        "    tfds_info = tfds.builder(tfds_name).info\n",
        "    num_examples = tfds_info.splits['train'].num_examples * NUM_LANGS * 2\n",
        "    train_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices(in_memory_ds)\n",
        "        .flat_map(\n",
        "            lambda x: tf.data.Dataset.from_tensor_slices(\n",
        "                tf.concat([\n",
        "                    tf.reshape(x['hypothesis']['translation'], [-1]),\n",
        "                    tf.stack([x['premise'][lang] for lang in LANGS], axis=0),\n",
        "                ], axis=0)\n",
        "            )\n",
        "        )\n",
        "        .shuffle(num_examples, reshuffle_each_iteration=True)\n",
        "        .batch(batch_size)\n",
        "        .map(lambda x: (student_preprocessor(x), teacher_preprocessor(x)))\n",
        "    )\n",
        "    return train_ds, num_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0adEDZEyW4Lj"
      },
      "source": [
        "student_preprocessor = create_student_preprocessing_model()\n",
        "teacher_preprocessor = create_teacher_preprocessing_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JPnV41xXOgp",
        "outputId": "00cd092c-bc5e-4f77-e19f-82e220edc876"
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    train_ds, num_examples = get_xnli_dataset(student_preprocessor, teacher_preprocessor, BATCH_SIZE)\n",
        "    print(\"Num examples:\", num_examples)\n",
        "    steps_per_epoch = STEPS_PER_EPOCH  # math.ceil(num_examples / BATCH_SIZE)\n",
        "    print(\"steps per epoch:\", steps_per_epoch)\n",
        "    num_train_steps = steps_per_epoch * EPOCHS\n",
        "    print(\"total num steps:\", num_train_steps)\n",
        "\n",
        "    student_model = create_student_model()\n",
        "    teacher_model = create_teacher_model()\n",
        "    model = ModelForKD(student_model, teacher_model)\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=['cosine_similarity'],\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=BertScheduler(LEARNING_RATE, WARMUP_RATE, num_train_steps)),\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_ds.repeat().prefetch(tf.data.AUTOTUNE),\n",
        "        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "        epochs=EPOCHS,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 11777100\n",
            "steps per epoch: 1000\n",
            "total num steps: 10000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_mask (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_word_ids (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      {'pooled_output': (N 134734080   input_mask[0][0]                 \n",
            "                                                                 input_word_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 768)          590592      keras_layer_2[0][6]              \n",
            "==================================================================================================\n",
            "Total params: 135,324,672\n",
            "Trainable params: 135,324,672\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_mask (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_word_ids (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_3 (KerasLayer)      {'sequence_output':  470926849   input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "                                                                 input_word_ids[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 470,926,849\n",
            "Trainable params: 0\n",
            "Non-trainable params: 470,926,849\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/PartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"Adam/gradients/PartitionedCall:0\", shape=(None, 768), dtype=float32), dense_shape=Tensor(\"Adam/gradients/PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 558s 461ms/step - loss: 0.1038 - cosine_similarity: 0.7361\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0440 - cosine_similarity: 0.9024\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0361 - cosine_similarity: 0.9209\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0321 - cosine_similarity: 0.9301\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0294 - cosine_similarity: 0.9363\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0274 - cosine_similarity: 0.9409\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0257 - cosine_similarity: 0.9446\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0243 - cosine_similarity: 0.9479\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0231 - cosine_similarity: 0.9504\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 460s 460ms/step - loss: 0.0222 - cosine_similarity: 0.9524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqXRuKC6ZJ6q",
        "outputId": "85e71636-6afe-435c-ac31-369b6006d3e5"
      },
      "source": [
        "MODEL_PATH = \"./model/distilmbert-for-representation\"\n",
        "\n",
        "# Save everything on the Colab host (even the variables from TPU memory)\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "student_model.save(MODEL_PATH, include_optimizer=False, options=save_options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 450). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/distilmbert-for-representation/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/distilmbert-for-representation/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYa5cZO556H8",
        "outputId": "09bda208-6cc1-4900-9422-0d70f1d09875"
      },
      "source": [
        "!zip -r model.zip model/distilmbert-for-representation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: model/distilmbert-for-representation/ (stored 0%)\n",
            "updating: model/distilmbert-for-representation/keras_metadata.pb (deflated 86%)\n",
            "updating: model/distilmbert-for-representation/assets/ (stored 0%)\n",
            "updating: model/distilmbert-for-representation/variables/ (stored 0%)\n",
            "updating: model/distilmbert-for-representation/variables/variables.index (deflated 79%)\n",
            "updating: model/distilmbert-for-representation/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "updating: model/distilmbert-for-representation/saved_model.pb (deflated 92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu0DHNT2ZylB",
        "outputId": "ee54be1f-6e77-4ed3-9415-50e15151a8a6"
      },
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# Langs:\n",
        "# French, Spanish, German, Greek, Bulgarian,\n",
        "# Russian, Turkish, Arabic, Vietnamese, Thai,\n",
        "# Chinese, Hindi, Swahili, Urdu\n",
        "!rm -rf data/tatoeba/v1\n",
        "!mkdir -p data/tatoeba/v1\n",
        "LANGS_TO_EVALUATE = [\n",
        "    \"fra\", \"spa\", \"deu\", \"ell\", \"bul\",\n",
        "    \"rus\", \"tur\", \"ara\", \"vie\", \"tha\",\n",
        "    \"cmn\", \"hin\", \"urd\"]\n",
        "\n",
        "for lang in LANGS_TO_EVALUATE:\n",
        "    !curl -L \"https://raw.githubusercontent.com/facebookresearch/LASER/2aa9cf8242f1030282be23a9cfa906fd011c4b2d/data/tatoeba/v1/tatoeba.{lang}-eng.{lang}\" -o \"./data/tatoeba/v1/tatoeba.{lang}-eng.{lang}\"\n",
        "    !curl -L \"https://raw.githubusercontent.com/facebookresearch/LASER/2aa9cf8242f1030282be23a9cfa906fd011c4b2d/data/tatoeba/v1/tatoeba.{lang}-eng.eng\" -o \"./data/tatoeba/v1/tatoeba.{lang}-eng.eng\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 43727  100 43727    0     0   261k      0 --:--:-- --:--:-- --:--:--  261k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 36291  100 36291    0     0   217k      0 --:--:-- --:--:-- --:--:--  217k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 37490  100 37490    0     0   245k      0 --:--:-- --:--:-- --:--:--  244k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 34776  100 34776    0     0   246k      0 --:--:-- --:--:-- --:--:--  246k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 57121  100 57121    0     0   338k      0 --:--:-- --:--:-- --:--:--  340k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 48446  100 48446    0     0   197k      0 --:--:-- --:--:-- --:--:--  197k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 52202  100 52202    0     0   236k      0 --:--:-- --:--:-- --:--:--  236k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 26759  100 26759    0     0   145k      0 --:--:-- --:--:-- --:--:--  144k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 65500  100 65500    0     0   292k      0 --:--:-- --:--:-- --:--:--  292k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 36779  100 36779    0     0   234k      0 --:--:-- --:--:-- --:--:--  236k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 58822  100 58822    0     0   377k      0 --:--:-- --:--:-- --:--:--  377k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 33650  100 33650    0     0   217k      0 --:--:-- --:--:-- --:--:--  217k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 37607  100 37607    0     0   253k      0 --:--:-- --:--:-- --:--:--  253k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 34278  100 34278    0     0   206k      0 --:--:-- --:--:-- --:--:--  206k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 43582  100 43582    0     0   295k      0 --:--:-- --:--:-- --:--:--  295k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 29068  100 29068    0     0   156k      0 --:--:-- --:--:-- --:--:--  156k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 52721  100 52721    0     0   282k      0 --:--:-- --:--:-- --:--:--  282k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 38686  100 38686    0     0   200k      0 --:--:-- --:--:-- --:--:--  200k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 44759  100 44759    0     0   188k      0 --:--:-- --:--:-- --:--:--  187k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18439  100 18439    0     0   121k      0 --:--:-- --:--:-- --:--:--  121k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 33410  100 33410    0     0   236k      0 --:--:-- --:--:-- --:--:--  236k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 35521  100 35521    0     0   202k      0 --:--:-- --:--:-- --:--:--  204k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 88468  100 88468    0     0   472k      0 --:--:-- --:--:-- --:--:--  472k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 34090  100 34090    0     0   221k      0 --:--:-- --:--:-- --:--:--  223k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 56819  100 56819    0     0   324k      0 --:--:-- --:--:-- --:--:--  324k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31893  100 31893    0     0   217k      0 --:--:-- --:--:-- --:--:--  217k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7u4ewKjZ1no",
        "outputId": "5216de67-fefc-48f2-fe61-c8aea8393aa2"
      },
      "source": [
        "from absl import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "@tf.function\n",
        "def encode_sentences_teacher(s):\n",
        "    return tf.nn.l2_normalize(teacher_model(teacher_preprocessor(s)), axis=-1)\n",
        "\n",
        "@tf.function\n",
        "def encode_sentences_student(s):\n",
        "    return tf.nn.l2_normalize(student_model(student_preprocessor(s)), axis=-1)\n",
        "\n",
        "for lang in LANGS_TO_EVALUATE:\n",
        "    with tf.device('/job:localhost'):\n",
        "        ds = [\n",
        "            (src.numpy(), tgt.numpy()) for src, tgt in tf.data.Dataset.zip((\n",
        "                tf.data.TextLineDataset([f\"./data/tatoeba/v1/tatoeba.{lang}-eng.eng\"]).batch(128),\n",
        "                tf.data.TextLineDataset([f\"./data/tatoeba/v1/tatoeba.{lang}-eng.{lang}\"]).batch(128),\n",
        "            ))\n",
        "        ]\n",
        "\n",
        "    src_embeddings_student = []\n",
        "    tgt_embeddings_student = []\n",
        "\n",
        "    src_embeddings_teacher = []\n",
        "    tgt_embeddings_teacher = []\n",
        "    for src, tgt in tqdm(ds):\n",
        "        src_embeddings_student.append(encode_sentences_student(src).numpy())\n",
        "        tgt_embeddings_student.append(encode_sentences_student(tgt).numpy())\n",
        "        src_embeddings_teacher.append(encode_sentences_teacher(src).numpy())\n",
        "        tgt_embeddings_teacher.append(encode_sentences_teacher(tgt).numpy())\n",
        "\n",
        "    def print_score(srs, tgt):\n",
        "        src_embeddings = tf.concat(srs, axis=0)\n",
        "        tgt_embeddings = tf.concat(tgt, axis=0)\n",
        "\n",
        "        similarities_src_to_tgt = tf.tensordot(src_embeddings, tgt_embeddings, axes=[[1], [1]])\n",
        "        answer = tf.range(tf.shape(src_embeddings)[0], dtype=tf.int64)\n",
        "        src_to_tgt_acc = tf.math.count_nonzero(tf.argmax(similarities_src_to_tgt, axis=-1) == answer) / tf.size(answer, tf.int64)\n",
        "        tgt_to_src_acc = tf.math.count_nonzero(tf.argmax(tf.transpose(similarities_src_to_tgt, perm=[1, 0]), axis=-1) == answer) / tf.size(answer, tf.int64)\n",
        "        # Print accuracy\n",
        "        print(f\"eng->{lang}:\", src_to_tgt_acc, f\", {lang}->eng:\", tgt_to_src_acc)\n",
        "\n",
        "    print(\"Student\")\n",
        "    print_score(src_embeddings_student, tgt_embeddings_student)\n",
        "    print(\"Teacher\")\n",
        "    print_score(src_embeddings_teacher, tgt_embeddings_teacher)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:28<00:00, 11.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->fra: tf.Tensor(0.951, shape=(), dtype=float64) , fra->eng: tf.Tensor(0.953, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->fra: tf.Tensor(0.959, shape=(), dtype=float64) , fra->eng: tf.Tensor(0.96, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:22<00:00, 10.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->spa: tf.Tensor(0.982, shape=(), dtype=float64) , spa->eng: tf.Tensor(0.985, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->spa: tf.Tensor(0.981, shape=(), dtype=float64) , spa->eng: tf.Tensor(0.988, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->deu: tf.Tensor(0.987, shape=(), dtype=float64) , deu->eng: tf.Tensor(0.986, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->deu: tf.Tensor(0.993, shape=(), dtype=float64) , deu->eng: tf.Tensor(0.994, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->ell: tf.Tensor(0.942, shape=(), dtype=float64) , ell->eng: tf.Tensor(0.943, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->ell: tf.Tensor(0.967, shape=(), dtype=float64) , ell->eng: tf.Tensor(0.965, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->bul: tf.Tensor(0.944, shape=(), dtype=float64) , bul->eng: tf.Tensor(0.94, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->bul: tf.Tensor(0.955, shape=(), dtype=float64) , bul->eng: tf.Tensor(0.959, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->rus: tf.Tensor(0.944, shape=(), dtype=float64) , rus->eng: tf.Tensor(0.942, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->rus: tf.Tensor(0.953, shape=(), dtype=float64) , rus->eng: tf.Tensor(0.953, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->tur: tf.Tensor(0.982, shape=(), dtype=float64) , tur->eng: tf.Tensor(0.979, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->tur: tf.Tensor(0.983, shape=(), dtype=float64) , tur->eng: tf.Tensor(0.985, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->ara: tf.Tensor(0.881, shape=(), dtype=float64) , ara->eng: tf.Tensor(0.887, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->ara: tf.Tensor(0.907, shape=(), dtype=float64) , ara->eng: tf.Tensor(0.912, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->vie: tf.Tensor(0.964, shape=(), dtype=float64) , vie->eng: tf.Tensor(0.966, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->vie: tf.Tensor(0.978, shape=(), dtype=float64) , vie->eng: tf.Tensor(0.979, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:48<00:00,  9.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->tha: tf.Tensor(0.8156934306569343, shape=(), dtype=float64) , tha->eng: tf.Tensor(0.8211678832116789, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->tha: tf.Tensor(0.8284671532846716, shape=(), dtype=float64) , tha->eng: tf.Tensor(0.8357664233576643, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->cmn: tf.Tensor(0.955, shape=(), dtype=float64) , cmn->eng: tf.Tensor(0.94, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->cmn: tf.Tensor(0.961, shape=(), dtype=float64) , cmn->eng: tf.Tensor(0.963, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:21<00:00, 10.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->hin: tf.Tensor(0.966, shape=(), dtype=float64) , hin->eng: tf.Tensor(0.956, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->hin: tf.Tensor(0.979, shape=(), dtype=float64) , hin->eng: tf.Tensor(0.976, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [01:22<00:00, 10.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student\n",
            "eng->urd: tf.Tensor(0.94, shape=(), dtype=float64) , urd->eng: tf.Tensor(0.934, shape=(), dtype=float64)\n",
            "Teacher\n",
            "eng->urd: tf.Tensor(0.96, shape=(), dtype=float64) , urd->eng: tf.Tensor(0.947, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}